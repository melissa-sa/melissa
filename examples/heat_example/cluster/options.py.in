###################################################################
#                            Melissa                              #
#-----------------------------------------------------------------#
#   COPYRIGHT (C) 2017  by INRIA and EDF. ALL RIGHTS RESERVED.    #
#                                                                 #
# This source is covered by the BSD 3-Clause License.             #
# Refer to the  LICENCE file for further information.             #
#                                                                 #
#-----------------------------------------------------------------#
#  Original Contributors:                                         #
#    Theophile Terraz,                                            #
#    Bruno Raffin,                                                #
#    Alejandro Ribes,                                             #
#    Bertrand Iooss,                                              #
###################################################################


"""
    User defined options module
"""
import os
import time
import numpy as np
import subprocess
import getpass
import imp
#from matplotlib import pyplot as plt
#from matplotlib import cm
from string import Template
from shutil import copyfile
import batchspawner
import job_scheduler_config  ## overwriting batchspawner defaults
import asyncio


spawner = job_scheduler_config.spawner

USERNAME = getpass.getuser()
BUILD_WITH_MPI = '@BUILD_WITH_MPI@'.upper()
EXECUTABLE='heatc'
NODES_SERVER = 1
NODES_GROUP = 1
WALLTIME_SERVER = "0:10:00"
WALLTIME_SIMU = "0:05:00"
NODES_SIMU = NODES_GROUP
PROC_PER_NODE = 1

def draw_param_set():
    param_set = np.zeros(STUDY_OPTIONS['nb_parameters'])
    for i in range(STUDY_OPTIONS['nb_parameters']):
        param_set[i] = np.random.uniform(0, 1)
    return param_set

def launch_server(server):
    if (not os.path.isdir(STUDY_OPTIONS['working_directory'])):
        os.mkdir(STUDY_OPTIONS['working_directory'])
    os.chdir(STUDY_OPTIONS['working_directory'])
    #create_run_server(server)
    server_cmd = "mpirun -n "+str(PROC_PER_NODE*NODES_SERVER) + " " +server.path+"/melissa_server "+server.cmd_opt # +" &"

    ## TODO: JS
#    content = ""  ## from jsc
#    file = open("@EXAMPLES_DIR@/heat_example/study_cluster/scripts/run_server.sh", "r")
#    content = Template(file.read()).substitute(WALLTIME_SERVER=str(WALLTIME_SERVER),
#                                               NODES_SERVER=str(NODES_SERVER),
#                                               PROC_PER_NODE=str(PROC_PER_NODE),
#                                               SERVER_CMD=str(server_cmd))
#    file.close()
#    file=open("run_server.sh", "w")
#    file.write(content)
#    file.close()
#    os.system("chmod 744 run_server.sh")
#    template_file = open("@EXAMPLES_DIR@/heat_example/study_cluster/job_scheduler_config.py", "r")
#    content = Template(template_file.read()).substitute(  ## TODO: jinja?
#        SERVER_CMD=str(server_cmd),
#        JOB_ID=spawner.job_id)
#    template_file.close()
#    template_file = open("@EXAMPLES_DIR@/heat_example/study_cluster/job_scheduler_config.py", "w")
#    template_file.write(content)
#    template_file.close()
    spawner.batch_script = spawner.server_script
    spawner.batch_script += Template('''date +\"%d/%m/%y %T\"
source @CMAKE_INSTALL_PREFIX@/bin/melissa_set_env.sh
# run Melissa
echo  \"### Launch Melissa\"
mkdir stats${JOB_ID}.resu
cd stats${JOB_ID}.resu
${SERVER_CMD}
# wait %1
date +\"%d/%m/%y %T\"
cd ..
''').substitute(  ## TODO: jinja?
        SERVER_CMD=str(server_cmd),
        JOB_ID=spawner.job_id)
    asyncio.get_event_loop().run_until_complete(
        spawner.submit_batch_script())

#    proc = subprocess.Popen(spawner.batch_submit_cmd + ' "./run_server.sh"',
#                                  stdout=subprocess.PIPE,
#                                  stderr=subprocess.PIPE,
#                                  shell=True,
#                                  universal_newlines=True)
#    # get the job ID
#    (out, err) = proc.communicate()
#    if len(out.split()) > 0:
#        server.job_id = out.split()[-1]
#    else:
#        print(err)
    server.job_id = spawner.job_id
    os.chdir(STUDY_OPTIONS['working_directory'])

def launch_simu(simulation):
    if (not os.path.isdir(STUDY_OPTIONS['working_directory']+"/simu"+str(simulation.rank))):
        os.mkdir(STUDY_OPTIONS['working_directory']+"/simu"+str(simulation.rank))
    os.chdir(STUDY_OPTIONS['working_directory']+"/simu"+str(simulation.rank))
    copyfile(STUDY_OPTIONS['working_directory']+'/server_name.txt' , './server_name.txt')
    if MELISSA_STATS['sobol_indices']:
        command = 'mpirun '
        for i in range(STUDY_OPTIONS['nb_parameters'] + 2):
            command += ' '.join(('-n',
                                 str(NODES_GROUP),
                                 '@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                 str(simulation.simu_id[i]), str(simulation.coupling),
                                 ' '.join(str(j) for j in simulation.param_set[i]),
                                 ': '))
        command = command[:-2]
    else:
        command = 'mpirun '
        for i in range(simulation.size):
            command += ' '.join(('-n',
                                 str(PROC_PER_NODE*NODES_SIMU),
                                 '@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                 str(simulation.simu_id[i]), str(simulation.coupling),
                                 ' '.join(str(j) for j in simulation.param_set[i]),
                                 ': '))
        command = command[:-2]
    print(command)

    ## TODO: JS
    # content = ""
    # file = open("@EXAMPLES_DIR@/heat_example/study_cluster/scripts/run_simu.sh", "r")
    # content = spawner.simu_script
    # content += Template(file.read()).substitute(SIMU_ID=str(simulation.rank),
    #                                            SIMU_CMD=str(command),
    #                                            SERVER_NODE_NAME=simulation.server_node_name,
    #                                            HOSTNAME=str("$(hostname)"))
    # file.close()
    # file=open("run_simu.sh", "w")
    # file.write(content)
    # file.close()
    # os.system("chmod 744 run_simu.sh")
    spawner.batch_script = spawner.simu_script
    spawner.batch_script += Template('''#SBATCH --job-name=Simu${SIMU_ID}
source @CMAKE_INSTALL_PREFIX@/bin/melissa_set_env.sh
export MELISSA_SERVER_NODE_NAME=${SERVER_NODE_NAME}
export MELISSA_MASTER_NODE_NAME=${HOSTNAME}
date +\"%d/%m/%y %T\"
${SIMU_CMD}
date +\"%d/%m/%y %T\"
''').substitute(SIMU_ID=str(simulation.rank),
               SIMU_CMD=str(command),
               SERVER_NODE_NAME=simulation.server_node_name,
               HOSTNAME=str("$(hostname)"))
    asyncio.get_event_loop().run_until_complete(
        spawner.submit_batch_script())

    # proc = subprocess.Popen(spawner.batch_submit_cmd + ' ' + spawner.job_name + 'Simu'+str(simulation.rank)+' "./run_simu.sh"',
    #                               stdout=subprocess.PIPE,
    #                               stderr=subprocess.PIPE,
    #                               shell=True,
    #                               universal_newlines=True)
    # # get the job ID
    # (out, err) = proc.communicate()
    # if len(out.split()) > 0:
    #     simulation.job_id = out.split()[-1]
    # else:
    #     print(err)
    simulation.job_id = spawner.job_id
    os.chdir(STUDY_OPTIONS['working_directory'])

def check_job(job):
    """
    0 - pending, 1 - running, 2 - not in queue
    """
    state = 0
    if not spawner.state_ispending():  ## not pending...
        state = 1
        if not spawner.state_isrunning():  ## ...and not running either
            state = 2
    job.job_status = state

def check_load():
    proc = subprocess.Popen(spawner.batch_query_cmd + STUDY_OPTIONS['user_name']+" | wc -l",
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            shell=True,
                            universal_newlines=True)
    (out, err) = proc.communicate()
    running_jobs = int(out)
    return running_jobs < 250

def kill_job(job):  ## TODO: check if such methods are replaceable
    print('killing job ...')
    os.system(spawner.batch_cancel_cmd + str(job.job_id))

STUDY_OPTIONS = {}
STUDY_OPTIONS['user_name'] = USERNAME
STUDY_OPTIONS['working_directory'] = '@EXAMPLES_DIR@/heat_example/study_cluster/STATS'
STUDY_OPTIONS['nb_parameters'] = 5                 # number of varying parameters of the study
STUDY_OPTIONS['sampling_size'] = 6                 # initial number of parameter sets
STUDY_OPTIONS['nb_timesteps'] = 100               # number of timesteps, from Melissa point of view
STUDY_OPTIONS['threshold_values'] = 0.7
STUDY_OPTIONS['quantile_values'] = [0.05,0.25,0.5,0.75,0.95]
STUDY_OPTIONS['field_names'] = ["heat1"]           # list of field names
STUDY_OPTIONS['simulation_timeout'] = 40           # simulations are restarted if no life sign for 40 seconds
STUDY_OPTIONS['checkpoint_interval'] = 20          # server checkpoints every 30 seconds
STUDY_OPTIONS['coupling'] = "MELISSA_COUPLING_MPI" # option for Sobol' simulation groups coupling

MELISSA_STATS = {}
MELISSA_STATS['mean'] = True
MELISSA_STATS['variance'] = True
MELISSA_STATS['skewness'] = True
MELISSA_STATS['kurtosis'] = True
MELISSA_STATS['min'] = True
MELISSA_STATS['max'] = True
MELISSA_STATS['threshold_exceedance'] = False
MELISSA_STATS['quantiles'] = False
MELISSA_STATS['sobol_indices'] = False

USER_FUNCTIONS = {}
USER_FUNCTIONS['create_study'] = None
USER_FUNCTIONS['draw_parameter_set'] = draw_param_set
USER_FUNCTIONS['create_group'] = None
#if MELISSA_STATS['sobol_indices']:
#    USER_FUNCTIONS['launch_group'] = launch_group
#else:
USER_FUNCTIONS['launch_group'] = launch_simu
USER_FUNCTIONS['launch_server'] = launch_server
USER_FUNCTIONS['check_server_job'] = check_job
USER_FUNCTIONS['check_group_job'] = check_job
USER_FUNCTIONS['restart_server'] = launch_server
USER_FUNCTIONS['restart_group'] = None
USER_FUNCTIONS['check_scheduler_load'] = check_load
USER_FUNCTIONS['cancel_job'] = kill_job
USER_FUNCTIONS['postprocessing'] = None
USER_FUNCTIONS['finalize'] = None
